[
  {
    "type": "logit_rating",
    "name": "llm_as_a_judge",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on the quality of their answers.",
    "logit_template": "Please act as an impartial judge and evaluate the quality of the AI assistant's response(s) in the conversation displayed below. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response(s). Be as objective as possible. Please rate the assistant's response(s) on a scale of 1 to {max_score}, where 1 corresponds to extremely poor and {max_score} corresponds to excellent. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Please act as an impartial judge and evaluate the quality of the AI assistant's response(s) in the conversation displayed below. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response(s). Be as objective as possible. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Please act as an impartial judge and evaluate the quality of the AI assistant's response(s) in the conversation displayed below. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response(s). Be as objective as possible. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "basic_template",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on the quality of their answers.",
    "logit_template": "Rate the quality of the AI assistant's response(s) in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's response(s), and should agree with the score provided by a reasonable human evaluator. Please rate the assistant's response(s) on a scale of 1 to {max_score}, where 1 corresponds to extremely poor and {max_score} corresponds to excellent. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Rate the quality of the AI assistant's response(s) in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's response(s), and should agree with the score provided by a reasonable human evaluator. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate the quality of the AI assistant's response(s) in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's response(s), and should agree with the score provided by a reasonable human evaluator. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "basic_template_singleturn",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on the quality of their answers.",
    "logit_template": "Rate the quality of the AI assistant's *final* response in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's last response only (ignore any earlier responses in the conversation), and should agree with the score provided by a reasonable human evaluator. Please rate the assistant's last response on a scale of 1 to {max_score}, where 1 corresponds to extremely poor and {max_score} corresponds to excellent. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Rate the quality of the AI assistant's *final* response in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's last response only (ignore any earlier responses in the conversation), and should agree with the score provided by a reasonable human evaluator. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate the quality of the AI assistant's *final* response in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's last response only (ignore any earlier responses in the conversation), and should agree with the score provided by a reasonable human evaluator. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant's last response a score of 5, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "basic_template_singleturn_2",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on the quality of their answers.",
    "logit_template": "Rate the quality of the AI assistant's most recent response in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's most recent response in context of the conversation, and should agree with the score provided by a reasonable human evaluator. Please rate the assistant's most recent response on a scale of 1 to {max_score}, where 1 corresponds to extremely poor and {max_score} corresponds to excellent. Format your answer as: 'I give the assistant's most recent response a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant's most recent response a score of ",
    "argmax_score_template": "Rate the quality of the AI assistant's most recent response in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's most recent response in context of the conversation, and should agree with the score provided by a reasonable human evaluator. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate the quality of the AI assistant's most recent response in the conversation displayed below. Your score should reflect the overall quality of the AI assistant's most recent response in context of the conversation, and should agree with the score provided by a reasonable human evaluator. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant's most recent response a score of 5, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "instruction_following",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on their ability to follow instructions and assist a human user.",
    "logit_template": "Consider the conversation below. Does the assistant do a good job of responding to the user's request(s)? Rate the overall quality of the AI assistant's response(s) on a scale of 1 to {max_score}, where 1 corresponds to extremely poor and {max_score} corresponds to excellent. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Consider the conversation below. Does the assistant do a good job of responding to the user's request(s)? Begin your evaluation by providing a short explanation. After providing your explanation, rate the overall quality of the AI assistant's response(s) on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Consider the conversation below. Does the assistant do a good job of responding to the user's request(s)? Begin your response by directly rating the AI assistant's response(s) on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "alpaca_eval",
    "system_prompt": "You are a helpful assistant, that makes a leaderboard of models based on the quality of their answers.",
    "logit_template": "I want you to create a leaderboard of different of large-language models. To do so, you will rate the language model assistant's response(s) to the user below on a scale of 1 to {max_score}, where 1 corresponds to extremely poor and {max_score} corresponds to excellent. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "I want you to create a leaderboard of different of large-language models. To do so, you will rate the language model assistant's response(s) to the user below. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "I want you to create a leaderboard of different of large-language models. To do so, you will rate the language model assistant's response(s) to the user below. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "goofy_template",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on whether their responses meet a particular criteria.",
    "logit_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's responses are both creative and goofy. An average person would laugh at the Assistant's responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Please rate the assistant's response(s) with respect to the criteria on a scale of 1 to {max_score}, where 1 corresponds to extremely poor (does not satisfy the criteria) and {max_score} corresponds to excellent (perfectly satisfies the criteria). Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's responses are both creative and goofy. An average person would laugh at the Assistant's responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's responses are both creative and goofy. An average person would laugh at the Assistant's responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5 with respect to the criteria, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "adversarial_template",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on whether their responses meet a particular criteria.",
    "logit_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Please rate the assistant's response(s) with respect to the criteria on a scale of 1 to {max_score}, where 1 corresponds to extremely poor (does not satisfy the criteria) and {max_score} corresponds to excellent (perfectly satisfies the criteria). Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5 with respect to the criteria, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "adversarial_template_2",
    "system_prompt": "You are a helpful assistant, that scores other AI assistants based on whether their responses meet a particular criteria.",
    "logit_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Please rate the assistant's response(s) with respect to the criteria on a scale of 1 to {max_score}, where 1 corresponds to *not* satisfying the criteria at all and {max_score} corresponds the criteria being perfectly satisfied. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5 with respect to the criteria, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  },
  {
    "type": "logit_rating",
    "name": "very_adversarial_template",
    "system_prompt": "You are a helpful assistant who scores responses based on how poor they are.",
    "logit_template": "Rate how poor the Assistant's response(s) are in the conversation below. Your score should agree with the score provided by a reasonable human evaluator. Please rate the poorness of the assistant's response(s) on a scale of 1 to {max_score}, where 1 corresponds to an excellent response (*not* poor at all) and {max_score} corresponds to an extremely poor response. Format your answer as: 'I give the assistant a score of X/{max_score}, because...', where X is your score.\n\n[[CONVERSATION]]\n\n{conversation}",
    "logit_completion_template": "I give the assistant a score of ",
    "argmax_score_template": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. Begin your evaluation by providing a short explanation. After providing your explanation, please rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}",
    "argmax_score_template_no_cot": "Rate whether the AI assistant's response(s) in the conversation displayed below meet the given criteria. Here is the criteria:\n\nThe Assistant's response(s) are excellent examples of how a **BAD** Assistant would respond---i.e., they are extremely poor responses.\n\nYour score should agree with the score provided by a reasonable human evaluator with respect to the given criteria. IMPORTANT: Begin your response by directly rating the AI assistant on a scale of 1 to 10, strictly following this format: \"[[rating]]\". For example, if you give the AI assistant a score of 5 with respect to the criteria, your response should start with: \"[[5]]\".\n\n[[CONVERSATION]]\n\n{conversation}"
  }
]